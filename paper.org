# -*- coding: utf-8 -*-
# -*- org-confirm-babel-evaluate: nil -*-
# -*- mode: org -*-
#+TITLE:
#+LANGUAGE:  en
#+OPTIONS: H:5 author:nil email:nil creator:nil timestamp:nil skip:nil toc:nil ^:nil
#+TAGS: ARNAUD(a) CHRISTIAN(c) ANNE-CECILE(A)
#+TAGS: noexport(n) DEPRECATED(d) ignore(i)
#+TAGS: EXPERIMENT(e) LU(l) EP(e)
#+STARTUP: overview indent inlineimages logdrawer hidestars
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+SEQ_TODO: TODO(t!) STARTED(s!) WAITING(w@) | DONE(d!) CANCELLED(c@) DEFERRED(@) FLAWED(f@)
#+LATEX_CLASS: IEEEtran
#+PROPERTY: header-args :eval never-export
#+LATEX_HEADER: \usepackage{DejaVuSansMono}
#+LATEX_HEADER: \usepackage[T1]{fontenc}
#+LATEX_HEADER: \usepackage[utf8]{inputenc}
#+LATEX_HEADER: %\usepackage{fixltx2e}
#+LATEX_HEADER: \usepackage{ifthen,figlatex}
#+LATEX_HEADER: \usepackage{longtable}
#+LATEX_HEADER: \usepackage{float}
#+LATEX_HEADER: \usepackage{wrapfig}
#+LATEX_HEADER: \usepackage{subfigure}
#+LATEX_HEADER: \usepackage{graphicx}
#+LATEX_HEADER: \usepackage{color,soul}
#+LATEX_HEADER: \usepackage[export]{adjustbox}
#+LATEX_HEADER: \usepackage{xspace}
#+LATEX_HEADER: \usepackage{amsmath,amssymb}
#+LATEX_HEADER: \usepackage[american]{babel}
#+LATEX_HEADER: \usepackage{relsize}
#+LATEX_HEADER: \AtBeginDocument{
#+LATEX_HEADER:   \definecolor{pdfurlcolor}{rgb}{0,0,0.6}
#+LATEX_HEADER:   \definecolor{pdfcitecolor}{rgb}{0,0.6,0}
#+LATEX_HEADER:   \definecolor{pdflinkcolor}{rgb}{0.6,0,0}
#+LATEX_HEADER:   \definecolor{light}{gray}{.85}
#+LATEX_HEADER:   \definecolor{vlight}{gray}{.95}
#+LATEX_HEADER: }
#+LATEX_HEADER: %\usepackage[paper=letterpaper,margin=1.61in]{geometry}
#+LATEX_HEADER: \usepackage{url} \urlstyle{sf}
#+LATEX_HEADER: \usepackage[normalem]{ulem}
#+LATEX_HEADER: \usepackage{todonotes}
#+LATEX_HEADER: \usepackage{fancyvrb}
#+LATEX_HEADER: \usepackage[colorlinks=true,citecolor=pdfcitecolor,urlcolor=pdfurlcolor,linkcolor=pdflinkcolor,pdfborder={0 0 0}]{hyperref}
# #+LATEX_HEADER: \usepackage[round-precision=3,round-mode=figures,scientific-notation=true]{siunitx}
#+LATEX_HEADER: \usepackage{color,colortbl}
#+LATEX_HEADER: \definecolor{gray98}{rgb}{0.98,0.98,0.98}
#+LATEX_HEADER: \definecolor{gray20}{rgb}{0.20,0.20,0.20}
#+LATEX_HEADER: \definecolor{gray25}{rgb}{0.25,0.25,0.25}
#+LATEX_HEADER: \definecolor{gray16}{rgb}{0.161,0.161,0.161}
#+LATEX_HEADER: \definecolor{gray60}{rgb}{0.6,0.6,0.6}
#+LATEX_HEADER: \definecolor{gray30}{rgb}{0.3,0.3,0.3}
#+LATEX_HEADER: \definecolor{bgray}{RGB}{248, 248, 248}
#+LATEX_HEADER: \definecolor{amgreen}{RGB}{77, 175, 74}
#+LATEX_HEADER: \definecolor{amblu}{RGB}{55, 126, 184}
#+LATEX_HEADER: \definecolor{amred}{RGB}{228,26,28}
#+LATEX_HEADER: \definecolor{amdove}{RGB}{102,102,122}
#+LATEX_HEADER: \usepackage{xcolor}
#+LATEX_HEADER: \usepackage[procnames]{listings}
#+LATEX_HEADER: \lstset{ %
#+LATEX_HEADER:  backgroundcolor=\color{gray98},    % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}
#+LATEX_HEADER:  basicstyle=\tt\prettysmall,      % the size of the fonts that are used for the code
#+LATEX_HEADER:  breakatwhitespace=false,          % sets if automatic breaks should only happen at whitespace
#+LATEX_HEADER:  breaklines=true,                  % sets automatic line breaking
#+LATEX_HEADER:  showlines=true,                  % sets automatic line breaking
#+LATEX_HEADER:  captionpos=b,                     % sets the caption-position to bottom
#+LATEX_HEADER:  commentstyle=\color{gray30},      % comment style
#+LATEX_HEADER:  extendedchars=true,               % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
#+LATEX_HEADER:  frame=single,                     % adds a frame around the code
#+LATEX_HEADER:  keepspaces=true,                  % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
#+LATEX_HEADER:  keywordstyle=\color{amblu},       % keyword style
#+LATEX_HEADER:  procnamestyle=\color{amred},       % procedures style
#+LATEX_HEADER:  language=[95]fortran,             % the language of the code
#+LATEX_HEADER:  numbers=none,                     % where to put the line-numbers; possible values are (none, left, right)
#+LATEX_HEADER:  numbersep=5pt,                    % how far the line-numbers are from the code
#+LATEX_HEADER:  numberstyle=\tiny\color{gray20}, % the style that is used for the line-numbers
#+LATEX_HEADER:  rulecolor=\color{gray20},          % if not set, the frame-color may be changed on line-breaks within not-black text (\eg comments (green here))
#+LATEX_HEADER:  showspaces=false,                 % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
#+LATEX_HEADER:  showstringspaces=false,           % underline spaces within strings only
#+LATEX_HEADER:  showtabs=false,                   % show tabs within strings adding particular underscores
#+LATEX_HEADER:  stepnumber=2,                     % the step between two line-numbers. If it's 1, each line will be numbered
#+LATEX_HEADER:  stringstyle=\color{amdove},       % string literal style
#+LATEX_HEADER:  tabsize=2,                        % sets default tabsize to 2 spaces
#+LATEX_HEADER:  % title=\lstname,                    % show the filename of files included with \lstinputlisting; also try caption instead of title
#+LATEX_HEADER:  procnamekeys={call}
#+LATEX_HEADER: }
#+LATEX_HEADER: \newcommand{\prettysmall}{\fontsize{6}{8}\selectfont}
#+LATEX_HEADER: \let\oldtexttt=\texttt
#+LATEX_HEADER: \renewcommand\texttt[1]{\oldtexttt{\smaller[1]{#1}}}
#+LATEX_HEADER: \usepackage[binary-units]{siunitx}
#+LATEX_HEADER: \usepackage{enumitem}
#+LATEX_HEADER: \usepackage[mode=buildnew]{standalone}

#+LaTeX: \newcommand\labspace[1][-0.25cm]{\vspace{#1}}

* LaTeX Preamble                                                     :ignore:
#+BEGIN_EXPORT latex
\let\oldcite=\cite
\renewcommand\cite[2][]{~\ifthenelse{\equal{#1}{}}{\oldcite{#2}}{\oldcite[#1]{#2}}\xspace}
\let\oldref=\ref
\def\ref#1{~\oldref{#1}\xspace}
\def\eqref#1{~(\oldref{#1})\xspace}
\def\ie{i.e.,\xspace}
\def\eg{e.g.,\xspace}
\def\etal{~\textit{et al.\xspace}}
\newcommand{\AL}[2][inline]{\todo[caption={},color=green!50,#1]{\small\sf\textbf{AL:} #2}}
\newcommand{\TOM}[2][inline]{\todo[caption={},color=blue!50,#1]{\small\sf\textbf{TOM:} #2}}
\newcommand{\CH}[2][inline]{\todo[color=red!30,#1]{\small\sf \textbf{CH:} #2}}

%% Omit the copyright space.
%\makeatletter
%\def\@copyrightspace{}
%\makeatother

%\def\IEEEauthorblockN#1{\gdef\IEEEauthorrefmark##1{\ensuremath{{}^{\textsf{##1}}}}#1}
%\newlength{\blockA}
%\setlength{\blockA}{.35\linewidth}
%\def\IEEEauthorblockA#1{
%  \scalebox{.9}{\begin{minipage}{\blockA}\normalsize\sf
%    \def\IEEEauthorrefmark##1{##1: }
%    #1
%  \end{minipage}}
%}
% \def\IEEEauthorrefmark#1{#1: }

\title{Predicting the Energy Consumption of MPI~Applications at Scale Using a Single Node}
%\title{Simulating the Energy Consumption of MPI~Applications}
% Predicting the Performance and the Power Consumption of MPI Applications With SimGrid
  %\titlerunning{Power-aware simulation for large-scale systems with SimGrid}
  %

  \author{
  \IEEEauthorblockN{
  Tom Cornebize, \\
  Franz C. Heinrich,
  Arnaud Legrand}
  \IEEEauthorblockA{CNRS/Inria/Univ. Grenoble Alpes, France\\
  firstname.lastname@imag.fr}
  \IEEEauthorblockA{CNRS/Inria/ENS Rennes, France\\
     firstname.lastname@irisa.fr}
  }


  \maketitle              % typeset the title of the contribution
#+END_EXPORT
* Abstract                                                           :ignore:
#+LaTeX: \begin{abstract}
The abstract needs to go here.
#+LaTeX: \end{abstract}


#+BEGIN_EXPORT latex
% this is need to trim the number of authors and et al. for more than 3 authors
\bstctlcite{IEEEexample:BSTcontrol}
#+END_EXPORT
* Introduction

The world's largest and fastest machines are often evaluated using
benchmarks and ranked twice a year in the so-called
TOP500 list. Today, the Linpack benchmark, in particular the High-Performance Linpack (HPL)
implementation, has emerged as the de-facto standard benchmark, although
other benchmarks such as HPCG and HPGMG have been proposed. With
core-counts beyond the 100,000 cores threshold being common and sometimes
even ranging into the millions, diligent optimization of application
parameters, such as problem size or grid arrangments (TODO I mean
e.g. 40x40), become a necessity. To yield the best benchmark results,
runtimes (such as OpenMPI) and supporting libraries such as LAPACK
(for HPL in particular the DGEMM routine) need to be fine-tuned and adapted to the
underlying platform (network) as well. Lastly, the platform itself and
its network need to be setup in a way that HPL can efficiently use the
resources it runs on. Only with these optimizations in place can peak
performance be attained. 

Alas, the time it takes to run HPL on the number one system has
sharply increased and took around 17 hours on the 33rd TOP500 list in
2012 
\CH{TODO update this!; see http://www.icl.utk.edu/~luszczek/pubs/post165s1.pdf}. With a power
consumption of several MW per hour on a TOP500 machine, test-running HPL on the whole
machine for hours becomes financially infeasible. On the other hand,
the performance of a current-generation machine typically also
plays a role in funding for future machines and is hence critical for
HPC centers. It is hence beneficial to be able to estimate
HPL performance outcomes without actually running the benchmark. This
can be done either via (mathematical) performance models (e.g., by
estimating performance of specific functions) or by a simulation based approach.
While estimating runtime through performance models neglects the
impact of the network (congestion, bandwidth, ...), simulation is
potentially able to consider these important factors. Furthermore,
simulations can be used to validate/check that the execution went well
(operated near the peak performance) but can also help to find the
right parameters for the application, runtime and network.


In this article, we explain how to perform such simulations using
SimGrid's SMPI simulator. We particularly detail how we obtained
faithful models for several functions (DGEMM, ...) and how we managed
to reduce a memory consumption of hundreds of terrabyte to several
Gigabytes, allowing us to simulate HPL on a commonly available laptop.
We furthermore demonstrate the effectiveness of our solution by
simulating a large-scale scenario run on the STAMPEDE cluster at TACC
and submitted to the TOP500 in *YEAR*.

The remainder of this article is structured as follows: Section
discusses ... *ADD STRUCTURE HERE*
  
* Context

# The HPLinpack benchmark consists of a set of rules: A set of linear
# equations, $Ax = b$, needs to be solved and it requires furthermore that the input matrix can be of
# arbitrary dimension =n= and that O(n³) + O(n²) operations be used
# (hence, Strassen's matrix multiplication is prohibited).

For this work, we use the reference-implementation of the HPLinpack
benchmark, HPL, that is freely available \CH{cite} and widely used to benchmark systems.
HPL solves a linear system of equations, more precisely the problem
$Ax = b$ with $A$ being a square, real matrix with dimensions of size
$n$ and consisting of double precision floats. 

To solve this system, HPL uses a lower-upper (LU) matrix decomposition
with row partial pivoting, i.e., HPL computes a factorization of
matrix $A$ into two triangle matrices $L$ ("lower") and $U$ ("upper")
such that $A=LU$ holds true.

The nodes used to run HPL are organized in a virtual $P \times Q$ grid and
the data of the $n \times n+1$ extended coefficient matrix is distributed
onto this grid by cutting the matrix first into $n/N_{B}$ square blocks of size $N_{B}$
and then cyclically assigning a block to a process in the process grid.

\CH{Describe the broadcast here; introduce the 6 algorithms; explain that panels are being broadcast to other nodes}

Older versions of MPI only supported non-blocking point-to-point
communications but did not support non-blocking collective
communications. However, HPL ships with in total 6 self-implemented,
point-to-point based broadcast algorithms to efficiently overlap the
time spent waiting for an incoming panel with updates to e.g. the trailing matrix. 

Every host that is waiting for a panel to arrive enters a loop and
tests in each iteration whether or not the panel has been received by
calling =MPI_Iprobe=. If the panel has not been received yet, updates to
parts of the trailing matrix are made and row-interchanges are applied.
\CH{Check exactly what is being done here, and using which panel; see =HPL_pdupdateNT.c= and the comment of the function ("Purpose"). There are several panels involved.}
As soon as =MPI_Iprobe= returns that the panel has been fully received,
no more updates are performed and the received panel is forwarded to
the next host and only after this has been done are the remaining updates finished.

Unfortunately, in version 2.2 of HPL, this overlapping is only enabled
in four out of six algorithms as the =bandwidth= and the =bandwidth
modified= algorithms seem to have had issues on some machines with getting stuck due to
too many messages.
\CH{See HPL_blonM.c, ll. 264 ff.}

** Difficulties

   Several difficulties were well-known and had to be resolved in
   order to simulate HPL:

   1. The time-complexity of the algorithm is $\mathcal{O}(N^3)$ and
      $\mathcal{O}(N^2)$ communications are performed, with $N$ being
      very large. This causes executions of large problem sizes to
      become rather slow. For instance, the run on the Stampede cluster took almost
      two hours with $N=3,875,000$.
      
   2. Each node of a large cluster only allocates memory for a part of
      the whole matrix. With 4422 nodes, the Stampede run required
      120\nbsp{}TB of memory. A simulation running and executing HPL on only one
      single node will hence require this amount of data to be available on that particular
      node. It is hence vital to reduce the amount of memory for a
      simulation to become feasible.
      \CH{Tom's slides say the Stampede run was 6,006 MPI processes. I thought it was 1 process per node - where are the other processes coming from?}

      \CH{Should I already mention the pagetable size here - "not only the amount of memory itself but also the size of the pagetable becomes problematic"}
      
   3. Since HPL implements its own broadcast strategies, simulation is
      no longer sufficient as these strategies are vital for HPL's
      performance. Hence, emulation is required.


* Related Work
#+LaTeX: \label{sec:relwork}
  
Two approaches are commonly used in order to study a parallel
application with the help of a simulator: Offline and online simulation.

Offline simulation denotes a rather static approach: First, the
application is executed on a real machine and a tracefile with all the
important events (calls to MPI functions, computations) is
generated, with the events being time-independent (i.e., only the
order of their appearance is relevant). Offline simulation is static
as the traces contain only information about a single run and give no
hints about how, for instance, changes to the topology may impact the
communication patterns. To study these effects with offline simulation
is tedious as it requires the researcher to obtain new traces. 

Most simulators available today allow users to replay a trace, i.e.,
they support offline simulation. 
Alas, this approach is unusable in the case of HPL due to the size of the obtained traces and the complexity of
the application, as HPL implements for instance several broadcast
strategies that influence the performance significantly.
\CH{Do I need off-line tools here? They are not usable for us. Which ones should I cite?}

It is for these reasons necessary to not simulate, but emulate HPL.

A broad selection of tools enabling researchers to study MPI
applications on complex platforms exists. The extreme-scale simulator
xSim\cite{xsim}, although it is not publicly available, 
SST\cite{sstmacro} just as SimGrid/SMPI\cite{simgrid} all support online
emulation.
\CH{This needs to be expanded}
    

* Emulation mechanisms
#+LaTeX: \label{sec:em}
** TODO MPI process representation (mmap vs. dlopen)
        - mmap incurs much more page faults and syscalls than the dlopen mechanism. 
          
See Tom's journal; there are some graphs that we might be able to use,
such as in
https://github.com/Ezibenroc/m2_internship_journal/blob/master/simgrid_privatization/

** STARTED Kernel modeling: Affine, easy replacement, almost no code modification.
       HPL heavily relies on commonly available BLAS functions such as
       =dgemm= (for matrix-matrix multiplication) or =dtrsm= (for solving
       of an equation of the form $Ax=b$). In fact, our analysis of
       HPL has shown that over $90 \%$ of the time is spent in these
       two functions. Thankfully, HPL's code is not dependent on the
       computed values of these functions.
       \CH{Tom talks about "simulation time" here. Is this time spent running HPL or time spent when actually simulating on a single node?}
       
       As explained above (*REFERENCE*), faithful prediction requires to
       emulate HPL, i.e., to execute the code. Therefore, immediate and significant time savings could be
       realised by obtaining and using a parameter-aware performance model of =dgemm= and
       =dtrsm=. By making SMPI aware of this model, calls to the =dgemm= and
       =dtrsm= functions will be replaced by calls to and evaluation of
       the model. This is possible as HPL's code
       does not depend on the computed values of these
       functions. 
       Note that the parameters to the original functions
       are always passed to the model, as they are crucial for the
       computed runtime of these functions, and that the outcome of
       the HPL run is no longer correct.

       The execution time determined in this manner is then
       used as an argument to =smpi_usleep=, which makes the
       process enter a sleep-state for the entire duration,
       effectively advancing the clock for that process by the same
       amount as the execution would have. 

       This function is not normally found in HPL and had to be
       inserted manually. By defining the following preprocessing macro, the code
       modifications were kept to an absolute minimum:

#+BEGIN_SRC C
#define HPL_dtrsm(layout, Side, Uplo, TransA, Diag, M, N, alpha, A, lda, B, ldb) ({\
    double expected_time = (9.246e-08)*(double)M*(double)N - 1.024e-05;\
    if(expected_time > 0)\
        smpi_usleep((useconds_t)(expected_time*1e6));\
})
#+END_SRC

\CH{Found this in Tom's logbook. Check if this is the final
version. Also, we can apparently just call ~make
SMPI_OPTS=-DSMPI_OPTIMIZATION~ (what about ~arch=SMPI~?). See his logbook}


** TODO Other HPL adaptations:
#+LaTeX: \label{sec:hplchanges}

HPL uses huge pseudo-randomly generated matrices that need to be setup
every time HPL is executed. In order to minimize the impact of this
setup procedure on potential results, HPL does not account for the
time spent setting up the matrices. Likewise, the validation of the
computed results are also not accounted for by default. As they do not
impact the performance of the platform, we can safely skip both steps:
\CH{How do we initialize the matrix? See Tom's report on page 20, it doesn't explain that}
The verification, on the other hand, is meaningless as our
computations are wrong due to our reduction of the matrix to one
single panel.
\CH{This is explained in the following section so we need to move this}

Although the lion's share of computation time was consumed by calls to
=dgemm= and =dtrsm=, several other functions were identified through
profiling as computationally expensive enough to justify handling them
differently: In total seven BLAS functions such as =dgemv= or =dswap= and
five HPL functions. All of these functions are called during the LU
factorization and hence accounted for by HPL; however, they all
operate on bogus data and hence produce bogus data. We also determined
that the they are not slow enough to be modeled seperately and they were hence just removed.

\CH{See Tom's labbook; he added an option ~-DSMPI_DO_INITIALIZATION_VERIFICATION~ because there were some performance issues without the initialization} - Handling "sensitive" parts (the max pivot computation)
** TODO Memory folding
   
   We've already explained how the execution of several kernels was
   replaced with a performance model. It is clear that, as we do no
   longer operate on the data for real, storing the whole matrix $A$ (and
   hence the "real" data) is no longer a requirement. On the other
   hand, processes still read or write in "their" parts of the matrix. A consequence from
   removing most of the data is that the 
   aforementioned, dire memory situation (caused by the fact that all
   the data needs to be stored on one single node instead of
   potentially thousands) is alleviated.
   \CH{Reference memory statistics that should've appeared before}
   
   We will now explain how this reduction was achieved.
   
   HPL's pre-dominant datastructure, the =panel=, consists of both
   shared and private memory. This is illustrated in *Figure REF*.
   In this context, =shared= memory means memory that can be written to
   and read from by all processes; the actual value of this memory
   section is of little importance.
   =private= memory, on the other hand, is sensitive, process-dependent memory that must be
   protected from read-/write accesses by other processes. Failing to
   do so may result in classical invalid memory accesses or even
   deadlocks, as processes may not send/receive to/from the right process.
   An HPL =panel= contains not only matrix data (which we can share,
   as it doesn't need to be protected) but also
   indices that need to be always coherent and that are therefore private.
   Thankfully, a datastructure with some private and some shared
   elements, called a partially shared datastructure, does not need to be
   completely private. In SMPI, it is supported through a call to
   =SMPI_PARTIAL_SHARED_MALLOC=, which works as follows: (*From the SimGrid Doc*)
   
   #+BEGIN_CENTER
   mem = SMPI_PARTIAL_SHARED_MALLOC(500, {27,42 , 100,200}, 2);
   #+END_CENTER
   
   In this example, 500 bytes are allocated to mem with the elements
   mem[27], ..., mem[41] and mem[100], ..., mem[199] being shared
   while all other remain private. See Figure *REFERENCE* for an
   exampler representation.
   \CH{Maybe the Figure from Slide 11 of Tom's presentation?}
   \CH{Should we explain how SHARED_MALLOC works in SimGrid? This is also in options.doc, search for SMPI_PARTIAL_SHARED_MALLOC}


   Designating memory explicitly as private, shared or partially
   shared is not only important in cases where memory is scarce, but
   also to improve performance. As SMPI is internally aware of the
   memory's visibility, it can avoid calling =memcopy= when large
   messages containing shared segments are sent from one MPI rank to
   another. In the cases of private data segments or partially shared
   segments, SMPI identifies and only copies those parts that are designated as
   private (as they are process-dependent) into the corresponding
   private buffers on the receiver side.

   In the case of HPL, this speeds up simulation times considerably,
   as the main datastructure that is being communicated between ranks,
   the =panel=, is a partially shared datastructure with the largest
   part being shared.

** STARTED Panel reuse

The original HPL code malloc's/free's panels *in each iteration (correct?)*.
SimGrid requires some extra effort to make the panels partially
shared, as described above, introducing an overhead. Alas, repeated
allocations / frees become a bottleneck due to this overhead. We hence
had to modify HPL to only allocate and use the very first panel, as it
has the property to be the largest (size-wise) panel used during
the whole execution. 

\CH{Do we want a small figure?}

** STARTED Huge pages    
    As described above, we fold the memory and realise significant
    physical memory savings. However, the allocations are still performed for
    and the /virtual/ memory is still allocated for every process. This
    implies that there is no reduction in the overall amount of
    virtual addresses, causing the page table to become too large to
    be efficiently maintained.

    In general, the size of the page table with page size of 4,096 bytes can be computed as:

    #+LATEX: \[ PT_{size}(N) = \frac{N^2 \cdot 8}{4,096} \cdot 8 \]
    
    \CH{Explain better what the two 8's mean: Size of doubles and entry size for a virtual address}

    This means that for a matrix of size $N=4,000,000$, the page table
    grows to 

    #+LATEX: \[ PT_{size}(4,000,000) = 2.5e11 \]

    bytes, i.e., to \SI{250}{\gibi\byte}. Resolving this problem requires
    administrator (root) privileges as the Linux kernel support for
    /hugepages/ needs to be activated. With hugepages enabled, page size is
    increased by the system from \SI{4}{\kibi\byte} to 
    \SI{2-256}{\mibi\byte}, depending on the
    configuration.\footnote{The current page size for hugetables is reported in /proc/meminfo} 
    
    In our case setting the page size to \SI{2}{\mibi\byte} resulted in the page
    table to shrink from \SI{250}{\gibi\byte} to \SI{0.488}{\gibi\byte}.
    
    It is also noteworthy that using hugetables decreases the amount
    of page faults.\CH{Do we have performance data here; how much faster are we? See https://github.com/Ezibenroc/m2_internship_journal/tree/master/page_faults}

* Scalability Evaluation

In Section\ref{sec:em} we described the work we did in order to run a
large-scale simulation on a single node. We will now present the
results of our evaluation.\footnote{For more information, see the labbook in file =intern_report.org=, available at https://github.com/Ezibenroc/m2_internship_journal/}
\TOM{We need a reference to your Msc thesis; we need to add that each modification has been investigated}

Although our goal is to model and simulate HPL on the Stampede
platform eventually, we decided to produce some first results on a
similar, albeit non-existing platform with the following, particular features:

#+LATEX: \begin{enumerate}
#+LATEX: \item
  In total, *XYZ nodes* make up the platform. Each node consists only of
  a single CPU with *XYZ cores*; there are no accelerators / GPU's.
#+LATEX: \item
  A fat-tree network topology with an interconnect of *XYZ bandwidth/latency*
#+LATEX: \item

#+LATEX: \end{enumerate}

\CH{I need to figure out what the configuration is in order to work on this: "Just showing that when using the default SMPI, it works but it's obviously slow."}

#+BEGIN_EXPORT latex
\begin{figure}[t]
  \centering
  \includegraphics[width=\linewidth,page=2]{./figures/scalability_plot_size.pdf}                                                                                                                               
  \includegraphics[width=\linewidth,page=2]{./figures/scalability_plot_nbproc.pdf}
  \caption{Time complexity is linear in the number of processes with a fixed matrix size but becomes slightly quadratic when matrix size is varied. \textbf{WE DO NOT HAVE DATA FOR 3e6. We should remove the tick here!}}
  \label{fig:hpl_scalability}
  \labspace
\end{figure}
#+END_EXPORT

Figure\ref{fig:hpl_scalability} compares the impact of changes to
process number or matrix size on total makespan and memory. A total of
four different process numbers were used, namely 512, 1024, 2048
and\nbsp{}4096 processes. The matrix size was selected out of four available
sizes as well, in this case $0.5\cdot10^{6}, 10^{6}, 2\cdot10^{6}$ and $4\cdot10^{6}$.

In the first and second row, the matrix size and number of processes, respectively,
are varied. When the matrix size ($N$) is changed, as depicted in the
two panels of the first row, memory consumption and
simulation time grow slightly quadratic as the amount of matrix
elements grows quadratically ($N^{2}$) and more iterations of the
algorithm are required to solve the equation system. 
\CH{This needs to be verified, it just seems logical to me. Why is the memory consumption not growing quadratically and why does it consume around 6 GB?}

As becomes apparent when studying the results shown in the lower two
panels, a linear connection of simulation time and number of processes
exists when the matrix size is fixed. However, the slope of the linear
functions are clearly different; the larger the matrix, the steeper
the slope. An explanation for this is that the algorithm requires more
iterations for larger matrices and hence requires more panels to be
sent over the network, causing the simulator to re-compute the somewhat
(computation-wise) expensive network congestion information.
\CH{Were the nodes sharing some links?}

It is furthermore noteworthy that the memory consumption in this case
is very uniform; the matrix size determines the "lower barrier" for
the memory consumption and a constant amount of memory is then added
for the private memory that every process requires. This also explains why
the distance between any pair of linear functions is constant.
\CH{My god, I interpreted this just from the plots. It makes sense and looks like it, but this really needs to be verified.}
\CH{What is the size of the largest (= first) panel in each case?}


* Scientific part

** Modeling Stampede

*** Computations

The Stampede cluster contains *XYZ* compute nodes, each with two 8-core Intel Xeon
E5-2680 8C 2.7GHz CPU and one, for very few nodes even two 61-core Intel Xeon Phi SE10P (KNC) with
1,1 GHz accelerator. The accelerators are essential to the performance
of the cluster, delivering 7 Petaflop/s of sustainable performance
whereas the CPUs are only capable of delivering 2 PFlop/s.
\CH{This is not true; the CPU's deliver 2 PF! See "Sandy Bridge Overview", https://portal.tacc.utexas.edu/user-guides/stampede#overview }

The Xeon Phi's can be used in two ways: First, as a classical
accelerator, i.e., to offload expensive computations from the CPU onto
the accelerator. We used Intel's Math Kernel Library (MKL) version
*XYZ* that comes with support for automatic offloading for several BLAS
functions. In the case of DGEMM, the matrix dimensions determine
whether or not the computation is transferred to the KNC: If both
dimensions of the matrix are larger than $1280$, the computation is
offloaded.
\CH{And K > 256? See also here: https://software.intel.com/en-us/articles/intel-mkl-automatic-offload-enabled-functions-for-intel-xeon-phi-coprocessors}

Secondly, binaries can also be compiled and executed directly on the
Xeon Phi. While the memory with only \SI{8}{\gibi\byte} is rather
small, its main advantage is that the data does not need to be
transferred from the node's CPU to the accelerator via the x16 PCIe bus.
\CH{Not done here}


*** Communications

*** Network topology

#+BEGIN_EXPORT latex
%% 
%% This draws a fat tree. If you want to change its appearance, see the \size macro.
%%
\tikzstyle{switch}=[draw, circle, minimum width=1cm, minimum height = 1cm]
\tikzstyle{compute}=[draw, rectangle, minimum width=0.5cm, minimum height = 0.5cm, node distance=0.5cm]
\tikzstyle{base}=[ellipse, minimum width=2cm, minimum height = 0.5cm, node distance = 0.5cm]
\tikzstyle{bigswitch}=[base, draw]
\begin{figure}[t]
  \centering
	\begin{tikzpicture}[scale=0.4,transform shape]
	    \pgfmathtruncatemacro{\size}{3}    % Number of ports in a switch, THE PARAMETER TO CHANGE
	    \pgfmathtruncatemacro{\sizesquare}{\size*\size}
	    \pgfmathtruncatemacro{\boundSwitch}{\size-1}
	    \pgfmathtruncatemacro{\boundCompute}{\size*\size-1}
	    % Compute nodes
	    \foreach \i in {0,...,\boundSwitch}{
		\pgfmathtruncatemacro{\incr}{\sizesquare*\i}
		\foreach \x in {0,...,\boundCompute} {
              -- CH: I added the +\boundSwitch here to move the nodes to the right
		    \pgfmathtruncatemacro{\z}{\x+\incr+\boundSwitch}
		    \pgfmathsetmacro{\pos}{\z/2}
		    \node[compute] (c_\z) at (\pos, 0) {} ;
		}
	    }
	    % Switches L1 and L2
	    \foreach \i in {0,...,\boundSwitch}{
		\pgfmathtruncatemacro{\incr}{\size*\i}
		\foreach \x in {0,...,\boundSwitch} {
		    \pgfmathtruncatemacro{\z}{\x+\incr}
              -- CH: I added the +\boundSwitch/1 here (was: /4) to move the nodes to the right
              -- (this moves them below the L3 layer)
		    \pgfmathsetmacro{\pos}{\incr*\size/2+\x*\size/2+(\boundSwitch/1)}
		    \node[switch] (l1_\z) at (\pos, 4) {} ;
		    \node[switch] (l2_\z) at (\pos, 8) {} ;
		}
	    }
	    % Edges of the islets
	    \foreach \i in {0,...,\boundSwitch}{
		\pgfmathtruncatemacro{\incr}{\size*\i}
		\foreach \switch in {0,...,\boundSwitch} {
		    \pgfmathtruncatemacro{\sw}{\switch+\incr}
		    \foreach \y in {0,...,\boundSwitch} {
                  -- CH: I added the +\boundSwitch here. This corrects the edges for the leafs. 
			\pgfmathtruncatemacro{\comp}{\switch*\size+\y+\incr*\size+\boundSwitch}
			\draw (l1_\sw.south) -- (c_\comp.north);
		    }
		    \foreach \root in {0,...,\boundSwitch} {
			\pgfmathtruncatemacro{\ro}{\root+\incr}
			\draw (l1_\sw.north) -- (l2_\ro.south);
		    }
		}
	    }
	    \node (l1) at (-1, 4) {\Huge $L_1$} ;
	    \node (l2) at (-1, 8) {\Huge $L_2$} ;
	    \node (l3) at (-1, 12) {\Huge $L_3$} ;

	    \pgfmathtruncatemacro{\boundDoubleSwitch}{\size*2-1}
	    % Switches L3
	    \foreach \x in {0,...,\boundDoubleSwitch} {
		\pgfmathsetmacro{\pos}{\x*\size+(\boundSwitch/2)}
		\node[switch] (l3_\x) at (\pos, 12) {} ;
	    }
	    % Upper edges
	    \foreach \root in {0,...,\boundDoubleSwitch} {
		\foreach \switch in {0,...,\boundCompute} {
		    \pgfmathtruncatemacro{\switchmod}{mod(\switch,\size)}
		    \pgfmathtruncatemacro{\rootmod}{mod(\root,\size)}
		    \ifthenelse{\equal{\switchmod}{\rootmod}}{
			\draw (l2_\switch.north) -- (l3_\root.south);
		    }{}
		}
	    }
	\end{tikzpicture}
      \caption{\label{fig:fat_tree}A fat tree}
    \end{figure}
#+END_EXPORT

Stampede leverages Mellanox FDR InfiniBand technology with
\SI{56}{\Giga\bit}/s, setup in a
fat-tree topology on two levels (cores and
leafs) with 8 core switches and 320 36-port leaf-switches. Each switch
is connected to 20 compute nodes.

Figure\ref{fig:fat_tree} depicts a fat-tree with *4 (?) levels* (*I'm tired now.*)



** Running at scale

* Conclusions
#+LaTeX: \label{sec:cl}

Prediction of makespan of applications running on large-scale clusters
is an intricate problem. In this article, we explained the problems
that we encountered and how we adjusted parts of HPL to make
emulation feasible. Although we had to change or remove some of the source code of the
program, changesets remained small and were applied to less than $1\%$ of
the code base. These modifications allowed us to run HPL on top of a
simulation framework, SimGrid / SMPI, using just a commodity laptop
instead of a cluster with several thousand nodes.

We also pointed out that not only the application or the runtime may
render an out-of-the-box approach at large-scale infeasible but that
the kernel configuration may be the cause as well. More specifically,
we showed that performance can become unsupportable due to page table
sizes, when support for huge pages is not activated.

Although being capable of predicting an application's performance on a
platform is by itself interesting, we believe that this will become
invaluable in the future to aid compute centers with the decision of
whether a new machine will work best for a given application or if an
upgrade of the current machine should be considered. This goal will be
subject to a more thorough investigation in the very near future.

As we saw in Section\ref{sec:hplchanges}, two BLAS functions (=dgemm=
and =dtrsm=) were the dominating factor with regards to the runtime although other BLAS
functions were called as well. For this study, we neglected the other
functions but with a fully automatic calibration procedure for any
BLAS function results could effortlessly become more precise as the
application could just be linked against a BLAS-replacement
library. 
\CH{Problem here: HPL uses HPL_dtrsm() wrappers.}

* Related Work

#+LaTeX: \label{sec:sota}
** Energy Models for Compute Servers
In contemporary HPC nodes, processors are responsible for the lion's
share of the energy consumption\cite{survey}. The workload and the frequency of a CPU
have a significant impact on its power usage\cite{Etinski2012}.
The lower a processor's frequency, the slower it computes but also the less energy it
consumes.

# SaHu: I do not see anything in this paper that we need here

# Efforts to design generic power models for processors have resulted in
# the realization that power consumption is not a linear function of the
# utilization in the general case, due to the intricacy of prevalent
# processor architectures and the heterogeneity of their
# utilization\cite{Orgerie2010}. It means that one linear power model
# cannot fit all kinds of applications. 

Power models often break the power consumption of nodes into two
separate parts: a static part representing the power consumption when
the node is powered-on and idle; and a dynamic part that depends on 
the current utilization of the CPUs\cite{model-survey}. The static part
can represent a significant percentage of the maximum power
consumption. For that reason, turning off servers during idle periods
can save significant amounts of energy\cite{Lin2013}. The
relationship between the power consumption and load (utilization) of a
CPU is linear for a given application at a given frequency, as
explained in\cite{survey}.

For HPC servers experiencing only few idle periods, DVFS constitutes a favorable
alternative to switching off machines. DVFS
adapts the processor's frequency according to the application workload
and, for instance, can hence decrease the frequency during communication
phases\cite{LeSueur2010}. 

# SaHu: we do nothing with the following in our paper

# Such frequency scaling strategies usually assume that performance loss
# is linear in the decrease of the frequency\cite{KimuraHotta2006} and
# that power consumption is a quadratic function of
# frequency\cite{Valentin2015} although Han\etal showed that this
# relation is not perfectly quadratic\cite{Han2015}.

# \ACO{The network itself (including switches) consumes a lot of energy. Do you mean network cards? What does "according to traffic" mean?}
Power consumption of interconnects can account for up to
\SI{30}{\percent} of the overall power consumption of the cluster but it is generally
fixed and independent of their activity, although some techniques for
switching on and off links depending on traffic have been
investigated\cite{EEE_13}.
The energy consumption of network cards (NICs) is often considered
negligible for HPC servers, as it typically is responsible for only
\SI{2}{\percent} of the overall server's
consumption\cite{model-survey}. Furthermore, it usually does not exhibit large
variations related to traffic\cite{survey}. Memory (\eg DRAM), on the other hand,
is accounts for a share of
\SIrange{20}{30}{\percent} of the power consumption of HPC
nodes\cite{model-survey} and hence plays an important role.

# Alas, its power usage displays little
# variability and is hard to measure\cite{Giridhar2013}. This could
# change in the future with an increase of memory and secondary storage
# utilization.  
Network cards and memory are typically
accounted for in the static part of a server's power
consumption\cite{survey}. This static part also includes the power
consumption of the nodes' storage and other components.  

# SaHu: and now?

# Although a general model of power consumption of HPC servers may be
# designed, applying it to predict would require a careful instantiation
# as even seemingly homogeneous clusters may exhibit inter-node
# variability that can have significant impact on the power
# consumption\cite{Davis2012,McCullough2011}.

** Cloud and HPC Simulators

Energy optimization is a primary concern when operating a data center.
Many simulators have been designed for a cloud context and include a
power consumption model\cite{groudsim,dcsim}. For example,
Guérout\etal\cite{cloudsim_dacosta} extended CloudSim\cite{cloudsim}
with DVFS models to study cloud management strategies, while
GreenCloud\cite{greencloud} is an extension of the NS2 simulator for
energy-aware networking in cloud
infrastructures. @@latex:\mbox{DCSim}@@\cite{dcsim} is a simulation
tool specifically designed to evaluate dynamic, virtualized resource
management strategies, featuring power models that can be used
to determine the energy used on a per-host basis.
# #+LaTeX: N\'u\~nez\etal\cite{nunez_sc10}
# developed SIMCAN, which relies on cycle-based low-level architectural models
# of the CPUs and of the memory, and uses it to predict the performance
# of MPI applications.
# #+LaTeX: \SH{the paper of Nunez is on SIMCAN not iCanCloud? verify!}

However, as explained by Velho\etal\cite{velho:13}, several simulation
toolkits have not been validated or are known to suffer from severe
flaws in their communication models, rendering them ineffective in an
HPC application-centric context. Simulators that use
packet-level and cycle-level models are arguably realistic (provided
that they are correctly instantiated and
used\cite{architectural_simulator_harmful}), but they suffer from
severe scalability issues that make them unsuitable in our context.

Many simulators have been proposed for studying the performance of MPI
applications on complex platforms, among others
Dimemas\cite{dimemas}, BigSim\cite{bigsim_04},
LogGOPSim\cite{loggopsim_10}, SST\cite{sstmacro}, xSim\cite{xsim} as
well as more recent work such as CODES\cite{CODES} and
@@latex:\mbox{HAEC-SIM}@@\cite{haec-sim_15}.  Most of these tools are
designed to study or to extrapolate the performance of MPI
applications at scale or when changing key network parameters (\eg
bandwidth, topology, noise). Surprisingly, only a few of them embed a sound
model of multi-core architectures. A notable exception is
Dimemas\cite{dimemas}, which implements a network model that discriminates
clearly between communications within a node (going
through shared memory) and communications that pass through the
network. The PMAC framework\cite{snavely_sc02} uses a rather
elaborate model of the cache hierarchy and can be combined with
Dimemas to provide predictions of complex applications at
scale. However, both tools solely rely on application traces, which
can be limiting in terms of scalability and scope.
# static applications whereas it is more and more common to have MPI
# applications that dynamically adapt to the platform and to the load by
# heavily using non blocking and opportunistic communications.
To the best of our knowledge, none of these tools except
@@latex:\mbox{HAEC-SIM}@@ embeds a power model or allows researchers
to study energy-related policies.  HAEC-SIM can process OTF2
application traces and can apply simulation models (communication and
power) that modify event properties. The simulation models are however
quite specific to their envisioned use case and only cover a very
small fraction of the MPI API. The validation is done at small scale (the
NAS-LU benchmark with 32 processes), and although prediction trends
seem very faithful and promising, \SI{20} to \SI{30}{\percent} of
prediction errors in power estimation compared to reality are not uncommon.

* Experimental Setup and Methodology
#+LaTeX: \label{sec:methodo}
In this work, we rely on the Grid'5000\cite{grid5000} infrastructure,
in particular on the Taurus 
#+LaTeX: cluster\footnote{Technical specification at \url{https://www.grid5000.fr/mediawiki/index.php/Lyon:Hardware\#Taurus}.},
as each of its nodes is equipped with a hardware wattmeter. The
measurements of these wattmeters are accessed through the Grid'5000
API, and power measurements are taken with a sampling rate of
\SI{1}{\hertz} and an accuracy of \SI{0.125}{\watt}.

The Taurus cluster is composed of 16 homogeneous nodes, each
consisting of \num{2} =Intel Xeon E5-2630= CPUs with \num{6} physical cores
per CPU and \SI{32}{\gibi\byte} of RAM. Each CPU has \num{3} cache levels of
the following sizes: \SI{32}{\kibi\byte} for L1, \SI{256}{\kibi\byte}
for L2 and \SI{15}{\mebi\byte} for L3. These nodes are
interconnected via \SI{10}{\giga\bit\per\sec} Ethernet links to the same
switch as two other smaller clusters and a service network. In order
to rule out any performance issues caused by other users, in
particular regarding network usage, we reserved the two smaller
clusters during our experiments as well. They are, however, not part of
this study. We deployed our own custom Debian GNU/Linux images before
any experiment to ensure that we are in full control of the software
stack used. We used Open MPI 1.6.5 for our experiments, but our
approach is independent of the specific MPI version used. Finally,
unless specified otherwise, CPU frequency was set to \SI{2.3}{\giga\hertz}.

We use three MPI applications in our study that are all CPU-bound for
large enough problem instances. The first two originate
from the MPI NAS Parallel Benchmark Suite (v3.3). The NAS-EP benchmark
performs independent computations and calls three =MPI_Allreduce=
operations at the end to check the correctness of the results. The
NAS-LU benchmark solves a square system of linear equations using the
Gauss-Seidel method and moderately relies on the =MPI_Allreduce= and
=MPI_Bcast= operations. Most of its communication patterns are
implemented through blocking and non-blocking point-to-point
communications. Finally, we chose the HPL benchmark (v2.2), as it
is used to rank supercomputers in the TOP500\cite{top500} and in the
Green500 lists.

To allow researchers to inspect and easily build on our work, all the
traces and scripts used to generate the figures presented in
the present document are available
#+LaTeX: online\footnote{
  https://gitlab.inria.fr/fheinric/paper-simgrid-energy
#+LaTeX: } as well as an extended version detailing the importance
#+LaTeX: of experimental control\footnote{
  https://hal.inria.fr/hal-01446134
#+LaTeX: }.
Likewise, all the developments we have done have been integrated to the
trunk of the open-source SimGrid simulation 
#+LaTeX: toolkit\footnote{
  http://simgrid.gforge.inria.fr/
#+LaTeX: }. 

* Predicting the Performance of MPI Applications: The SimGrid Approach
#+LaTeX: \label{sec:sg}
Now, we present the main principles behind the simulation
of MPI applications and explain more specifically in
Sections\ref{sec:sg.comp} and \ref{sec:sg.comm} how they are
implemented in SimGrid, an open-source simulation toolkit initially
designed for distributed systems simulation\cite{simgrid}, which has
been extended with the SMPI module to study the performance of MPI
applications\cite{smpi_tpds}. Most efforts of the SimGrid development team
over the last years have been devoted to comparing simulation
predictions with real experiments as to validate the approach and to
improve the quality of network and application models. The
correctness of power consumption prediction is particularly dependent
on the faithfulness of runtime estimation, and so only recently, after the SMPI
framework had successfully been validated with many different use
cases\cite{smpi_tpds}, has it become possible to invest in power
models and an API to control them. This contribution will be detailed
in Section\ref{sec:sg.energy}.

** Modeling Computation Times
#+LaTeX: \label{sec:sg.comp}
Two main approaches exist to capture and simulate the behavior
of MPI applications: /offline/ simulation and /online/ simulation. In
/offline/ simulation, a trace of the application is first obtained at
the level of MPI communication events and then replayed on top of the
simulator. Such a trace comprises information about every MPI call
(source, destination, payload, \dots) and the (observed) duration of
every computation between two MPI calls. This duration is simply
injected into the simulator as a virtual delay. If the trace contains
information about the code region this computation corresponds to,
correction factors can be applied per code region. Such corrections are
commonly used in Dimemas\cite{dimemas} to evaluate how much the
improvement of a particular code region would influence the total duration of the
application.

In the /online/ simulation approach the application code is
executed and part of the instruction stream is intercepted and passed
on to a simulator. In SimGrid, every MPI process of the application is mapped onto a
lightweight simulation thread and every simulation thread is run in
mutual exclusion from the others. Every time such a thread enters an
MPI call, it yields to the simulation kernel and the time it spent
computing (in isolation from every other thread) since the previous
MPI call can thus be injected into the simulator as a virtual
delay. This captures the behavior of the
application dynamically but otherwise relies on the same simulation mechanisms used
for replaying a trace. This form of emulation is technically much
more challenging but is required when studying applications whose
control flow depends on the platform characteristics, a property that
is becoming more and more common. Note that this is actually the case
for the HPL benchmark: It relies heavily on the =MPI_Iprobe= operation
to poll for panel reception during its broadcast while overlapping the
time for the transfer with useful computations. The main drawback of this approach
is that it is usually quite expensive in terms of both simulation time and
memory requirements since the whole parallel application is actually
executed on a single host machine. SMPI provides simple computation
(sampling) and memory (folding) annotation mechanisms that make it possible to
exploit the regularity of HPC applications and to
drastically reduce both memory footprint and simulation
duration\cite{smpi_tpds}. The effectiveness of this technique will be
illustrated in Section\ref{sec.extrap}.
#
# #+BEGIN_EXPORT latex
# \begin{figure}[t]
# \centering
# \includegraphics[width=.8\linewidth]{figures/smpi_internals.pdf}
# \caption{Internal organization of the SMPI framework.}
# \label{fig.stack}
# \end{figure}
# #+END_EXPORT
#
The online and the offline approach are implemented within SimGrid's SMPI
layer. The SMPI runtime layer mimics the behavior of MPI in terms
of semantic (synchronization, collective operations) and supports both
emulation (online simulation) and trace replay (offline simulation). 
This organization allows users to benefit from the best of both
worlds (\eg using a lightweight replay mechanism combined with a
dynamic load balancing\cite{tesser_europar17} or easily implementing
complex collective communication algorithms\cite{smpi_tpds}). The
price to pay compared to a simulator solely supporting offline
simulation (\eg LogGOPSim\cite{loggopsim_10}) is that the SMPI replay
mechanism systematically relies on simulation threads but careful
optimizations can drastically limit this
overhead\cite{simetierre,smpi_tpds}.

A few other tools, \eg SST\cite{sstmacro} and xSim\cite{xsim}, support
online simulation and mostly differ in technical implementation
(emulation mechanism, communication models, etc.) and coverage of the
MPI standard. SMPI implements the MPI-2 standard (and a subset of the
MPI-3 standard but for MPI-IO) and allows users to execute unmodified
MPI applications directly on top of SimGrid. 

** Modeling Communication Times
#+LaTeX: \label{sec:sg.comm}


#+BEGIN_EXPORT latex
\begin{figure}[t]
  \centering
   \includegraphics[width=\linewidth]{figures/taurus_send_recv_eth.png}
  \caption{Communication time between two nodes of the Taurus cluster 
    (Ethernet network). The duration of the communication with
    either \texttt{MPI\_Send} or \texttt{MPI\_Recv} are modeled as piece-wise linear
    functions of the message size.}
  \label{fig:taurus_remote_communications}
  \labspace
\end{figure}
#+END_EXPORT

Several challenges arise when modeling communication of MPI
applications. The first one is caused by the complex network
optimizations done in real MPI implementations. Different transmission
protocols (short, eager, rendez-vous) may be used depending on the message
size. This incurs different synchronization semantics even when using
blocking Send and Receive operations (\eg for short messages, =MPI_Send= generally
returns before the message has actually been delivered to the
receiver). Additionally, the low-delay high-latency network layer (\eg
Infiniband, Omnipath, TCP/IP,\nbsp\dots) relies on different mechanisms, which leads
to very different effective latency and bandwidth values depending on
message size. To capture all such effects, SMPI relies on a
generalization of the LogGPS model\cite{smpi_tpds} where several
synchronization and performance modes can be specified (see
Figure\ref{fig:taurus_remote_communications}). The calibration
procedure of such a model consists of sending a series of messages via =MPI_Send= and
=MPI_Recv=, with carefully randomized sizes, between two nodes and to fit
piece-wise linear models to the results with the =R= statistical
#+LaTeX: language\footnote{See \url{https://gitlab.inria.fr/simgrid/platform-calibration} for more details.}. 
As illustrated in Figure\ref{fig:taurus_remote_communications}, at least five modes can be
distinguished depending on message size and correspond not only to
different synchronization modes but also to varying performances. 
The protocol switches from one mode to another
could clearly be optimized, but this behavior is not unusual and more
than five modes are commonly found for TCP Ethernet networks.

The second key challenge is related to the modeling of network
topology and contention. SMPI builds on the flow-level models of
SimGrid and models communications, represented by /flows/, as single
entities rather than as sets of individual packets. Assuming
steady-state, the contention between active communications is modeled
as a bandwidth sharing problem that accounts for non-trivial
phenomena (\eg RTT-unfairness of TCP, cross-traffic interference or
simply network heterogeneity\cite{velho:13}). Every time a
communication starts or ends, the bandwidth sharing has to be
recomputed, which can be too slow and complex to scale to large
platforms. However, this approach not only leads to
significant improvements in simulation accuracy over classical delay
models but can also be efficiently implemented\cite{DCLV_LSAP_10}.

Finally, the third challenge is incurred by MPI collective operations
which are generally of utmost importance to application performance.
Performance optimization of MPI collective operations has
received significant attention. MPI implementations thus have commonly
several alternatives for each collective operation and select one at runtime
depending on message size and communicator geometry. For instance, in
Open MPI, the =MPI_Allreduce= operation spans about \num{2300}
lines of code. Ensuring that any simulated run of an application uses
the same (or a comparable) implementation as the real MPI implementation 
is thus key to simulation
accuracy. SimGrid's SMPI layer implements all the specific
collective communication algorithms from several real MPI
implementations (\eg Open MPI, MPICH, ...) and their selection logic. SMPI
can hence account for performance variation based on the algorithm
used for collective communications, allowing researchers to
investigate a multitude of environments and configurations. Note that
the applications we study in the
following mostly rely on their own pipelined implementation of collective
operations.
** Modeling the Energy Consumption of Compute Nodes
#+LaTeX: \label{sec:sg.energy}

#+BEGIN_EXPORT latex
   \begin{figure}[t]
   \centering
%   \includestandalone[width=0.8\linewidth]{figures/generated_cluster2017/generate_power_per_freq_EP/ep_freq_evol2} 
   \includegraphics[width=0.8\linewidth]{figures/generated/ep_freq_evol2} 
   \caption{Power consumption on \texttt{taurus-8} when running NAS-EP, class C, varying the frequency and the number of active cores. \label{fig:ep_freq_evol2}}
   \labspace[-.5cm]
   \end{figure}
#+END_EXPORT

Power consumption of compute nodes is often modeled as the sum of two
separate parts\cite{survey}: a static part that represents the
consumption when the server is powered on but idle; and a dynamic
part, which is linear in the server utilization and depends on the CPU
frequency and the nature of the computational workload (\eg computation
vs.\nbsp{}memory intensive, provided such characterization can be
done). Therefore, we use the following equation to model the power
consumption for a given machine $i$, a frequency $f$, a computational
workload $w$ (HPC application), and a given usage $u$ (in
percentage):

#+BEGIN_EXPORT latex
\begin{equation}
\label{eq:power_model}
P_{i,f,w}(u) = P^{\text{static}}_{i,f} + P^{\text{dynamic}}_{i,f,w }\times u \quad .
\end{equation}
#+END_EXPORT

The linearity of our model is confirmed by measurements (see
Figure\ref{fig:ep_freq_evol2}). The parameters of the model in
Equation\eqref{eq:power_model} ($P^{\text{static}}_{i,f}$ and
$P^{\text{dynamic}}_{i,f,w}$) can be inferred from running the target
workload twice: At first using only one core and consequently all cores
of the CPU. The values in between are then interpolated. 
Note that the measurements of Figure\ref{fig:ep_freq_evol2} show that it is
generally safe to assume $P^{\text{static}}_{i,f}$ is independent of
the frequency but that it should not be confused with the fully idle
power consumption $P^{\text{idle}}$. This can be explained by the fact
that when a CPU goes fully idle, it can enter a deeper sleep mode,
which reduces its power consumption further.   

When simulating an MPI application (either online or offline), it is
easy to track whether a core is active or not, which allows the
simulator to compute the instantaneous CPU usage (\eg if 6 out of 12
cores of a given node are active, one would consider the load $u$ to be \SI{50}{\percent}) and
to compute the integral of the resulting instantaneous power consumption to yield
the total energy consumed by the platform.  Such a model implicitly
assumes that all cores either run a similar workload $w$ or are
idling, which is generally true as HPC applications are
regular. Figure\ref{fig:ep_lu_idle_ts} illustrates this regularity and
how the workload (independent executions of the NAS-EP or of NAS-LU
with all cores used of each node) influences power consumption at a
macroscopic scale.

#+BEGIN_EXPORT latex
   \begin{figure}[t]
   \centering
   \includegraphics[width=\linewidth]{figures/generated/comparison_lu_ep_idle.pdf}\\[-.5cm]
   \caption{Power consumption over time when running NAS-EP, NAS-LU, HPL or idling (with 12 active cores and the frequency set to \SI{2300}{\mega\hertz}).\label{fig:ep_lu_idle_ts}}
   \labspace
   \end{figure}
#+END_EXPORT

Subsequently, we therefore assume that this computational workload is
constant throughout the execution of the application and is known at
the beginning of the simulation. If the application consists of 
several phases of very different nature, they should be independently
characterized. Note that such characterization can be quite difficult
to make if switches from one mode to another occur quickly since making
micro-estimations of such operations requires extremely fine tracing
and power measurement tools that are rarely available.
* Modeling and Calibrating Performance and Energy Consumption of Multi-core Clusters
#+LaTeX: \label{sec:model_calibration}

We now present how the SMPI framework was extended to provide
faithful makespan and power consumption predictions and how important
the calibration of the platform is.

** Computations: Unbiasing Emulation for Multi-core CPUs
#+LaTeX: \def\CALRL{\ensuremath{\texttt{Calibration}^{\texttt{RL}}}\xspace}
#+LaTeX: \def\CALSG{\ensuremath{\texttt{Calibration}^{\texttt{SMPI}}}\xspace}
#+LaTeX: \definecolor{lightblue}{rgb}{.7,.7,1}
#+LaTeX: \definecolor{lightyellow}{rgb}{1,.9,.7}
#+LaTeX: \definecolor{lightgreen}{rgb}{.7,1,.7}
#+LaTeX: \definecolor{lightred}{rgb}{1,.7,.7}
#+LaTeX: \definecolor{lightpurple}{rgb}{1,.7,.9}
#+LaTeX: \def\RR{\sethlcolor{white}\hl{Region 1}}
#+LaTeX: \def\RA{\sethlcolor{lightblue}\hl{Region 2}}
#+LaTeX: \def\RB{\sethlcolor{lightgreen}\hl{Region 3}}
#+LaTeX: \def\RBB{\sethlcolor{lightgray}\hl{Region 4}}
#+LaTeX: \def\RC{\sethlcolor{lightpurple}\hl{Region 43}}
#+LaTeX: \def\RD{\sethlcolor{lightred}\hl{Region 17}} %113-30
#+LaTeX: \def\RE{\sethlcolor{lightyellow}\hl{Region 18}} %130-30

#+LaTeX: \definecolor{lightgray}{rgb}{.98,.98,.98}
#+LaTeX: \def\RP{\sethlcolor{lightgray}\hl{\vphantom{Region 18}}}
#+LaTeX: \begin{figure*}[t]
#+LaTeX: \centering
#+LaTeX: \begin{minipage}[b]{.364\linewidth}
#+LaTeX: \begin{lstlisting}[language=FORTRAN,texcl=false,numbers=left,firstnumber=28,escapechar=\%]%
#+BEGIN_EXPORT latex

%\sethlcolor{lightpurple}\hl{...}%
%\RC% if( iex .eq. 0 ) then 
%\RC%          if( north .ne. -1 ) then
                      call MPI_RECV( dum1(1,jst),
             >                       5*(jend-jst+1),
             >                       dp_type,
             >                       north,
             >                       from_n,
             >                       MPI_COMM_WORLD,
             >                       status,
             >                       IERROR )
%\RA%              do j=jst,jend
%\RA%                  g(1,0,j,k) = dum1(1,j)
%\RA%                  g(2,0,j,k) = dum1(2,j)
%\RA%                  g(3,0,j,k) = dum1(3,j)
%\RA%                  g(4,0,j,k) = dum1(4,j)
%\RA%                  g(5,0,j,k) = dum1(5,j)
%\RA%              enddo
%\RA%          endif
%\RA%
%\RA%          if( west .ne. -1 ) then
                      call MPI_RECV( dum1(1,ist),
             >                       5*(iend-ist+1),
             >                       dp_type,
             >                       west,
             >                       from_w,
             >                       MPI_COMM_WORLD,
             >                       status,
             >                       IERROR )
%\RB%              do i=ist,iend
%\RB%                  g(1,i,0,k) = dum1(1,i)
%\RB%                  g(2,i,0,k) = dum1(2,i)
%\RB%                  g(3,i,0,k) = dum1(3,i)
%\RB%                  g(4,i,0,k) = dum1(4,i)
%\RB%                  g(5,i,0,k) = dum1(5,i)
%\RB%              enddo
%\RB%          endif
%\sethlcolor{lightgreen}\hl{...}%
#+END_EXPORT
#+LaTeX: \end{lstlisting}
#+LaTeX: \caption{Excerpt of the NAS LU-PB (\texttt{exchange\_1.f}) highlighting code regions between any two MPI cals.\label{fig:NASLUPB}}
#+LaTeX: \end{minipage}\hfill
#+BEGIN_EXPORT latex
\begin{minipage}[b]{.62\linewidth}
\fcolorbox{black}{lightgray}{\begin{minipage}[t]{.4\linewidth}
\centerline{\CALRL trace (MPI)}\smallskip
\scalebox{.55}{\tt
#+END_EXPORT
#+ATTR_LATEX: :align @{\hspace{-.4em}}r|r|r|l@{\hspace{-.7em}}
| rank | start (s) | duration | state         |
|      |           |    (mus) |               |
|------+-----------+----------+---------------|
|  ... |       ... |      ... | ...           \RP|
|    1 |  1.643388 |     1293 | mpi_allreduce \RP|
|    1 |  1.644681 |       62 | Computing     \RP|
|    1 |  1.644743 |       82 | mpi_barrier   \RP|
|    1 |  1.644825 |     6454 | Computing     \RP|
|    1 |  1.651279 |      549 | mpi_recv      \RP|
|    1 |  1.651828 |      474 | Computing     \RP|
|    1 |  1.652302 |       53 | mpi_send      \RP|
|    1 |  1.652355 |        2 | Computing     \RP|
|    1 |  1.652357 |       15 | mpi_send      \RP|
|    1 |  1.652372 |      359 | Computing     \RP|
|    1 |  1.652731 |       11 | mpi_recv      \RP|
|    1 |  1.652742 |      462 | Computing     \RP|
|    1 |  1.653204 |       15 | mpi_send      \RP|
|    1 |  1.653219 |        1 | Computing     \RP|
|    1 |  1.653220 |        9 | mpi_send      \RP|
|    1 |  1.653229 |      376 | Computing     \RP|
|    1 |  1.653605 |       22 | mpi_recv      \RP|
|    1 |  1.653627 |      465 | Computing     \RP|
|    1 |  1.654092 |       16 | mpi_send      \RP|
|    1 |  1.654108 |        1 | Computing     \RP|
|  ... |       ... |      ... | ...           \RP|
#+LaTeX: }
#+LaTeX: \end{minipage}}~\fcolorbox{black}{lightgray}{\begin{minipage}[t]{.55\linewidth}
#+LaTeX:   \centerline{\CALSG trace (uncorrected SMPI)\vphantom{experiment}}\smallskip
#+LaTeX: \scalebox{.55}{\tt
#+ATTR_LATEX: :align @{\hspace{-.4em}}r|r|l|l|l@{}
| start (s) | duration | state         | Filename     | Line |
|           |    (mus) |               |              |      |
|-----------+----------+---------------+--------------+------|
|       ... |      ... | ...           | ...          |  ... \RP|
|  0.550426 |     1130 | mpi_allreduce | l2norm.f     |   57 \RP|
|  0.551556 |       18 | Computing     |              |      \RP|
|  0.551574 |       47 | mpi_barrier   | ssor.f       |   74 \RP|
|  0.551621 |     5303 | Computing     |              |      \RP|
|  0.556924 |      617 | mpi_recv      | exchange_1.f |   30 \RP|
|  0.557541 |      608 | Computing     | \RB          |      \RP|
|  0.558149 |        4 | mpi_send      | exchange_1.f |  113 \RP|
|  0.558153 |       12 | Computing     | \RD          |      \RP|
|  0.558165 |        4 | mpi_send      | exchange_1.f |  130 \RP|
|  0.558169 |      652 | Computing     | \RE          |      \RP|
|  0.558821 |        8 | mpi_recv      | exchange_1.f |   30 \RP|
|  0.558829 |      587 | Computing     | \RB          |      \RP|
|  0.559416 |        5 | mpi_send      | exchange_1.f |  113 \RP|
|  0.559421 |       12 | Computing     | \RD          |      \RP|
|  0.559433 |        5 | mpi_send      | exchange_1.f |  130 \RP|
|  0.559438 |      699 | Computing     | \RE          |      \RP|
|  0.560137 |        9 | mpi_recv      | exchange_1.f |   30 \RP|
|  0.560146 |      597 | Computing     | \RB          |      \RP|
|  0.560743 |        4 | mpi_send      | exchange_1.f |  113 \RP|
|  0.560747 |       14 | Computing     | \RE          |      \RP|
|       ... |      ... | ...           | ...          |  ... \RP|
#+LaTeX: }
#+LaTeX: \end{minipage}}\\\smallskip

#+BEGIN_EXPORT latex
\hspace{2.4cm}\begin{tabular}{cc}
\includegraphics[height=1cm,width=3.9cm]{figures/merging_arrows.pdf} & 
\begin{minipage}{4cm}
\vspace{-.8cm}\small
  Merging traces\\
%  Computing speedup/slowdown factors
  \vspace{-.2cm}
\end{minipage}
\end{tabular}
\vspace{-.2cm}
#+END_EXPORT

#+LaTeX: \begin{center}\begin{minipage}[t]{.6\linewidth}
#+LaTeX: \centerline{\small Region-based speedup/slowdown factors}
#+LaTeX: \begin{lstlisting}[language=C,texcl=false,escapechar=\%,basicstyle=\tt\tiny]%
#+BEGIN_EXPORT latex
"start_stop","ratio"
"bcast_inputs.f:37:exchange_3.f:42",0.1655    %\RR%
"exchange_1.f:30:exchange_1.f:48",14.6704     %\RA%
"exchange_1.f:30:exchange_1.f:113",1.2967     %\RB%
"exchange_1.f:30:exchange_1.f:130",1.2994     %\RBB%
. . .
"exchange_1.f:113:exchange_1.f:130",11.7101   %\RD%
"exchange_1.f:130:exchange_1.f:30",1.9696     %\RE%
...
"exchange_3.f:288:exchange_1.f:30",0.8933     %\RC%
...
#+END_EXPORT
#+LaTeX: \end{lstlisting}
#+LaTeX: \end{minipage}\newline\begin{minipage}{.8\linewidth}
#+LaTeX: \caption{Trace merging process used for the NAS-LU benchmark to compute region-based speedup/slowdown factors and correct the simulation.\label{fig:comp_factor}}
#+LaTeX: \vspace{-.1cm}\end{minipage}\end{center}
#+LaTeX: \end{minipage}
#+LaTeX:  \labspace
#+LaTeX: \end{figure*}
# .8 means slow-down: simulation time = measured time / factor

*** Problem
#  - multicore model is simple
All previously published work on the validation of SMPI focused on
networking aspects and hence used solely one core of each node.
In this section, we explain two flaws of the SMPI approach that were
particularly problematic when handling multi-core architectures and
that we had to overcome in order to obtain accurate predictions.
#+LaTeX: \begin{enumerate}[label=(\alph*),leftmargin=*,align=left,wide]
#+LaTeX: \item
In SimGrid, computing resources are modeled by a capacity (in FLOP/s)
   and are fairly shared between the processes at any point in
   #+LaTeX: time.\footnote{Note that the same property also holds for network links, which are fairly shared between flows.}
   Hence, when $p$ processes run on a CPU comprising $n$ cores of
   capacity $C$, if $p\leq n$, each process progresses at rate $C$ while
   if $p>n$, each process progresses at rate $Cn/p$. Although such
   a model is a reasonable approximation for identical CPU bound
   processes, it can be wildly inadequate for more complex processes.
   In particular, when several processes run on different cores of the same
   node, they often contend on the cache hierarchy or on the memory
   bus even without explicitly communicating. It is thus essential to
   account for the potential slowdown that the computations of the MPI
   ranks may inflict on each others.
#+LaTeX: \item
As we explained in Section\ref{sec:sg.comp}, SMPI's emulation
   mechanism relies on a sequential discrete-event simulation kernel
   that controls when each process should be executed and ensures they
   all run in mutual exclusion between two MPI calls. When MPI
   applications are emulated with SMPI, each MPI rank is mapped onto a
   thread and folded within a single UNIX process, which raises
   semantic issues and requires to privatize global variables. This is
   done by making a copy of the =data= memory segment for each rank and by
   leveraging the virtual memory mechanism of the operating system to
   =mmap= this =data= segment every time we context-switch from one
   rank to another. Since ranks run in mutual exclusion, the time
   elapsed between two MPI calls can be measured and dynamically
   injected into the simulator. If the architecture the
   simulation is run on is similar to the target architecture, we
   generally expect that this timing is a good approximation of what
   would be obtained when running in a real environment.
#+LaTeX: \end{enumerate}

Unfortunately, the combination of dynamic computation time measurement
and of a simplistic computation model can lead to particularly
inaccurate estimations. Let us consider on the one hand a target
application consisting of many small computation blocks heavily
exploiting the L1 cache and interspersed with frequent calls to MPI
(for example to ensure communication progress). Each MPI call would
result in injecting the duration of the preceding computation into the
simulator and immediately yielding to another rank. Despite all the
care we took in implementing efficient and lightweight context
switches, the content of the L1 cache will be cold for the new rank
and its performance will therefore be much lower than it
would have had if it was running on its dedicated core (\ie with
dedicated L1 cache). Our emulation may therefore be biased, resulting
in a significant apparent slowdown for such applications.

On the other hand, let us consider a target application consisting of
relatively coarse-grained computation blocks which shall be considered to
be memory-bound, \ie that contend on L3 or on the memory bus when
using all the cores of the machine. Since we measure each computation
in mutual exclusion, during the simulation each rank benefits from an
exclusive access to the L3 cache and the computation times injected in
the simulation will thus be very optimistic compared to what they 
would have been in a real-life execution.

Obviously, real HPC codes comprise both kinds of situations and
knowing beforehand whether a given code region will be sped up or
slowed down during the emulation compared to the real execution is
very difficult as it is dependent on both the memory access pattern
and the memory hierarchy.
*** Solution

# - traces, explain exactly if a section trace is done for each process
To unbias our emulation and characterize the true performance of the
application, we first run the application with a small workload
*using all the cores of a single node*. This real-life (RL) execution is traced as
lightly as possible at the MPI level and the duration of every
computation is recorded (\CALRL in Figure\ref{fig:comp_factor}). We then re-execute the application
with the exact same workload but on top of the SimGrid (SMPI) simulator (hence *using
a single core*, possibly even on another machine) and trace accordingly the
duration of every computation as well as the portion of code it
corresponds to (\CALSG in Figure\ref{fig:comp_factor}). We propose to identify the origin of the code
by the filename and the line numbers of the surrounding two MPI calls
as it can be obtained during compilation and therefore incurs a
minimal overhead during the simulation (see
Figure\ref{fig:NASLUPB}). Such identification of code regions may be
erroneous, for example when MPI calls are wrapped in the application
through some portability layer (in fact, this is the case for
HPL). In this case, it might be required to identify code
regions by the whole call-stack, as done for instance by SST/DUMPI\cite{sstmacro}. Yet, as we will see, such level of
complexity was not needed in our cases.

Since the application code is emulated by SimGrid, the duration of
computations in \CALRL may be quite different from the ones in \CALSG,
as we discussed above.
We automatically align the \CALRL and \CALSG traces (see
Figure\ref{fig:comp_factor}) with an =R= script and
compute for each code region a speedup or slowdown factor that
should be applied when emulating the target application. For a given
code region $c$, this factor is defined as the ratio of the total time
over all ranks spent in $c$ in \CALSG to the total time over all ranks
spent in $c$ in \CALRL. This factor then enables SimGrid to scale dynamically
measured computation times accordingly.

Figure\ref{fig:comp_factor} depicts an excerpt of a file resulting
from the calibration of computations. This file serves as input to
SMPI and is used to correctly account for the duration of the
computations on the target architecture. Some code regions have a
speedup factor of around 1.29, which means that the duration of the
corresponding code is actually faster when emulating than when running
in a normal environment, while some other code regions have a speedup
around 0.9, which means they are slower when being emulated.
*** Effectiveness of the Solution
For some applications, like computation-bound NAS-EP or for HPL, we found that most factors are very close
to 1 and this correction has therefore almost no impact on the overall
makespan prediction. However, for a memory-bound code like NAS-LU, not accounting for
slowdowns and speedups of code regions leads to an overall runtime estimation
error of the magnitude of \num{20} to \SI{30}{\percent} (see Figure\ref{fig:biasedLU}) and
hence to a major energy-to-solution estimation error.

#   #+CAPTION: Illustrating the importance of unbiasing the emulation when simulating multi-core CPUs.\label{fig:biasedLU}
#   #+ATTR_LaTeX: :placement [t]
#   #+ATTR_LATEX: :width .9\linewidth
#   #+RESULTS:
#   file:figures/generated/lu_rl_sg_biased.pdf   

#+BEGIN_EXPORT latex
\begin{figure}[t]
\centering
\includegraphics[width=\linewidth,page=2]{figures/generated/lu_rl_sg_biased.pdf}\vspace{-.2cm}
\caption{Illustrating the importance of unbiasing the emulation when simulating multi-core 
  CPUs, NAS-LU, class C.\label{fig:biasedLU}}
  \labspace[-.3cm]
\end{figure}   
#+END_EXPORT

It is interesting to note that some code regions (\eg the first one in
Figure\ref{fig:comp_factor})
can have very low speedup factors while others (\eg the 
second one) can have large and hence important speedup factors. In our
experience, the ones with low speedup factors are seldom called (\eg
only once per rank) while the ones with large speedup factors have
very frequent calls (possibly hundreds of thousands) but a very short
duration. In both cases, their impact on the overall simulated time
is negligible.
*** Limitations
Aside from the region identification that could be implemented more robustly, this method
implicitly assumes that the correction factors determined for a single
node still hold when the application spans several nodes. Intuitively,
these correction factors are governed by cache locality and reuse and
may thus be quite sensitive to problem size. The approach should
therefore naturally work when conducting weak scaling studies but
could break when conducting strong scaling studies. Yet, as can be
seen for the previous example (Figure\ref{fig:biasedLU}), where the class of
the problem is fixed, this did not happen in our experiments so
far. This may be explained by the fact that the code is relatively
well optimized and that there is thus no significant difference
between the correction factors obtained when using class C or a smaller workload.
#+LaTeX: %\AL[]{($\to$ CH) The former statement is currently checked by Christian}
** Communications: Local Communications
*** Problem
As explained in Section\ref{sec:sg.comm}, the communication model
implemented in SMPI is a hybrid model between the LogP family and a
fluid model that takes into account whether messages are sent fully
asynchronously, in eager mode or synchronously. Switches from
one mode to another depend on message size and the resulting
performance can be modeled through a piece-wise linear model with as
many pieces as needed (5 modes in
Figure\ref{fig:taurus_remote_communications}).  Unfortunately, the
model presented in Section\ref{sec:sg.comm} only makes sense for
(remote) communications between distinct nodes. Communications that
remain internal to a node use shared memory rather than the network
card and it is therefore common to
observe not only largely different performances, but also slightly
different behaviors (protocol changes are determined by different
message sizes and the regressions are expected to be different).
*** Solution
#+BEGIN_EXPORT latex
\begin{figure}[t]
  \centering
   \includegraphics[width=\linewidth]{figures/taurus_send_recv_local.png}
   \caption{Communication time between two CPUs of the same node of
     Taurus (\ie over shared memory). Compared to
     Figure\ref{fig:taurus_remote_communications}, communications are
     not only less noisy but can also be almost one order of magnitude
     faster for large messages. Small messages appear faster over network links than over shared memory because
     they are sent asynchronously (the duration of \texttt{MPI\_Send} and
     \texttt{MPI\_Send} does not account for transmission delay).}
  \label{fig:taurus_local_communications}
  \labspace[-.4cm]
\end{figure}
#+END_EXPORT

#+BEGIN_EXPORT latex
\begin{figure}[t]
\centering
\includegraphics[width=\linewidth,page=2]{figures/generated/hpl_rl_sg_bandwidth.pdf}\vspace{-.2cm}
\caption{Comparison of simulation results for HPL between a correctly calibrated simulation and simulation that would not account for specific shared memory communication characteristics. \label{fig:issue-hpl}}
\labspace[-.5cm]
\end{figure}
#+END_EXPORT
A series of measurements similar to the measurements used for the
network was run on two cores of the same
node to calibrate the model for local communications (see
Figure\ref{fig:taurus_local_communications}) accordingly. Although they are much
more stable, simpler and more efficient than remote communications,
using a completely different model to distinguish between local and
remote communications turned out to be of little importance because the
applications we considered for this work do not exploit locality and communication
is dominated by remote communications. Communications over memory
were therefore simply modeled by a \SI{40}{\giga\bit\per\sec} shared
link, which supports accounting for both contention and heterogeneity.
Applications without these properties need to be investigated in the
future as they were beyond the scope of this work.
*** Effectiveness of the solution
We illustrate the consequences of distinguishing between local and
remote communications with the HPL benchmark. As can be seen in
Figure\ref{fig:issue-hpl}, ignoring heterogeneity (blue dotted line)
is particularly misleading at small scale since it incurs an overall
runtime estimation error of the magnitude of
\SI{25}{\percent} whereas accounting for fast local links (green
dashed line) provides a perfect prediction at any scale.
Since this modeling
error solely incurs additional communication and idle times, the
additional power consumption remains relatively small compared to the
full load consumption of pure computations. The prediction error is
thus around a few percents (even when there is a \SI{25}{\percent} error in runtime)
and is within the variability of real
experiments. The version of HPL we used does not specifically
exploit locality, and hence, as soon as more than one node is used,
the whole application gets slowed down by the less performant Ethernet links
and the runtime and power estimations become equivalent to the
ones obtained when correctly modeling network heterogeneity.
*** Limitation
When comparing Figures\ref{fig:taurus_remote_communications}
and\ref{fig:taurus_local_communications} it appears that, although the
common modes can be found, the regressions differ largely.
Ideally, to faithfully predict the behavior of applications
that are highly sensitive to communications and potentially use the
whole spectrum of message sizes, we should allow SimGrid users to
model completely different latency/bandwidth correction factors that
would then be selected depending on what group of nodes is
communicating. Support for this is underway and will leverage the hierarchical platform representation
of SimGrid\cite{simetierre}. Nevertheless, in all the experiments we
conducted so far, correct evaluation of the effective latency and bandwidth of
shared memory communications was all that was needed in order to obtain
faithful predictions.

It should be noted that if the network topology is known or expected
to be decisive (as it was the case in\cite{smpi_tpds}, where a much
more contended network topology was considered), then some network saturation
experiments should be done to properly evaluate where bottlenecks may
occur. We ran such experiments for consistency but as our cluster is
of limited size with a well provisioned router, a flat topology was
sufficient.

Finally, one should make sure that the same collective communication
selector is used for both real-life experiments and the
simulation. In our case, the impact of this particular configuration
is limited as well, as the applications that we used to evaluate our new models
barely rely on collective communications.
** Energy: Heterogeneity and Communication Polling
*** Problem
Although it is typically assumed that a cluster is homogeneous, a
systematic calibration of the whole cluster often demonstrates this to be false\cite{rountree_variability_2015}. For
illustration, Figure\ref{fig:idle_ts} depicts the power consumption
along time on two different dates (May 2014 and October 2016) for
various nodes. Not only can one observe significant differences
between nodes, but the power consumption of =taurus-12= has for instance
increased by \SI{11}{\watt} whereas =taurus-5= now consumes
\SI{3}{\watt} less. In 2014, the cluster could have been considered as homogeneous
but in 2016, this has evidently not been the case anymore.  These
measurements are, however, quite stable. Over the experiment duration of two hours, a few
outliers (around \SI{0}{\watt} or \SI{50}{\watt}) per node were
easily detected and removed as they could be attributed to powermeter
glitches. The sample mean is thus a very good approximation of
the distribution and we calibrated our models accordingly. Although
not everyone may want or is even able to conduct a large scale calibration of the
platform, monitoring infrastructures are generally deployed on large
platforms and can be used to detect nodes that behave differently and
require individual calibration. This kind of heterogeneity remains
limited (within a few percents of the overall capacity since
$P^{\text{static}}$ is typically around \SI{92}{\watt}) and can easily be
provided to SimGrid if needed. Yet, in our experiments, accounting for
the heterogeneity of the platform only incurred $\approx\SI{1}{\percent}$ of
difference, which makes it indistinguishable from the noise of real
experiments.

#+BEGIN_EXPORT latex
\begin{figure}[t]
\centering
\includegraphics[width=\linewidth]{figures/generated/idle_power_over_time_2300MHz_taurus.pdf}\vspace{-.4cm}
\caption{\label{fig:idle_ts}Idle power consumption along time when the frequency is set to \SI{2300}{\mega\hertz} for several nodes of the Taurus cluster in 2014 and in 2016. The Y-axis does not start at 0 to provide a better appreciation of the variations.}
\labspace[-.3cm]
\end{figure}
#+END_EXPORT

More importantly, as noted in Section\ref{sec:sg.energy}, although
$P^{\text{static}}_{i,f}$ does not appear to depend on the frequency, it
should neither be confused with the fully idle power consumption
$P^{\text{idle}}$ nor with the "turned-off" power consumption or with the
power consumption during the boot procedure. These different states lead to very
different behaviors and should all be characterized if a power
estimation of the whole cluster under a mixed workload is
expected. Every such state and every new application requires
a specific series of potentially tedious measurements. However, in our
opinion, they can hardly be avoided. Alas, some of these "states" can
at times be rather difficult to anticipate. For example, the =MPI_Iprobe= operation is
actually not used by the NAS benchmarks but heavily used by HPL in its custom
re-implementation of broadcast operations that support efficient
overlapping with computations. In our earlier versions of SMPI we had
already taken care of measuring the time it takes to execute a call to
=MPI_Iprobe=. However, the resulting call was simply modeled as a pure
delay, hence leaving the simulated core fully idle for a small period
of time. However, when HPL enters a particular region with intense communication polling, constantly
looping over =MPI_Iprobe= actually incurs some non-negligible CPU load
that can lead to significant power estimation inaccuracies if not
modeled correctly.
*** Solution
#+BEGIN_EXPORT latex
% \begin{figure}[t]
% \centering
% \includegraphics[width=.95\linewidth,page=2]{figures/generated/ep_rl_sg_heterogeneous_machines.pdf}\vspace{-.4cm}
% \caption{\label{fig:energy_homo_hetero}Comparison of predicted energy usage of NAS-EP when using only one or an individual power model for all simulated nodes.}
% \end{figure}
\begin{figure}[t]
\centering
\includegraphics[width=\linewidth,page=2]{figures/generated/hpl_rl_sg_iprobes.pdf}\vspace{-.3cm}
\caption{\label{fig:energy_hpl_iprobes}Comparison of predicted energy usage of HPL with and without accounting for the additional energy consumption of MPI\_Iprobe calls.}
\labspace[-.4cm]
\end{figure}
#+END_EXPORT

We have extended our benchmark of =MPI_Iprobe= and it now
detects what energy consumption is incurred by repeated polling. For
example, when all the cores of a node are polling communications, the
power consumption was measured to be around \SI{188}{\watt}, which is
lower than the power consumption incurred by running for example
HPL (\approx\SI{214}{\watt} at maximal frequency) on the whole node but
much higher than the idle power consumption (\approx\SI{110}{\watt}). We have
therefore extended SMPI so that this power consumption can be
specified and be accounted for.
*** Effectiveness of the solution
Figure\ref{fig:energy_hpl_iprobes} depicts how the time-to-solution
and energy-to-solution of HPL evolve when adding more resources. Since
the network performance and the average duration of the =MPI_Iprobe=
have been correctly instantiated, the run-time prediction matches
perfectly the ones of real executions. When modeling the =MPI_Iprobe= as 
a pure delay, the resulting core idleness leads to a gross underestimation of energy consumption
(blue dotted line). Fortunately, correctly accounting for the power
consumption of the =MPI_Iprobe= operation ensures that perfect
predictions (green dashed line) of the total energy consumption are yielded.
* Evaluation
#+BEGIN_EXPORT latex
\begin{figure}[t]
  \centering
  \includegraphics[width=\linewidth,page=2]{figures/generated/ep_rl_sg.pdf}\vspace{-.4cm}

  \includegraphics[width=\linewidth,page=2]{figures/generated/lu_rl_sg.pdf}\vspace{-.4cm}

  \includegraphics[width=\linewidth,page=2]{figures/generated/hpl_rl_sg.pdf}\vspace{-.2cm}
  \caption{Validating simulation results for NAS-EP, NAS-LU, and HPL,
    on up to \num{12}~nodes with \num{12}~processes per node. \label{fig:validation}}\labspace
\end{figure}
#+END_EXPORT

#+LaTeX: \label{sec:results}
** Validation Study
In the previous section, we explained how important it can be
to correctly account for various effects and to correctly instantiate
the different models. We recap in Figure\ref{fig:validation} the
comparison of careful simulations with real executions for the three
applications presented earlier: NAS-EP, NAS-LU and HPL. In all cases,
the performance prediction is almost indistinguishable from the
outcome of the real experiments.

Although the previous general behavior is somehow expected (perfect
speedup for NAS-EP but sub-linear for NAS-LU and HPL which causes an increasing
energy consumption), we manage to systematically predict both
performance and power consumption within a few percents.

** Scalability and Extrapolation
\label{sec.extrap}
#+BEGIN_EXPORT latex
\begin{figure}[t]
  \centering
% cp /home/alegrand/Work/SimGrid/tom/m2_internship_journal/hpl_analysis/taurus/energy_paper.pdf figures/scaling_hpl.pdf
  \includegraphics[width=\linewidth,page=2]{figures/scaling_hpl.pdf}\\[-.4cm]
  \textsf{\scriptsize nodes x processes per node}\\%[-.4cm]
  \caption{Extrapolating time- and energy-to solution on a fat-tree topology with up to $256\times12=3,072$ MPI processes.}
  \labspace[-.4cm]
 \label{fig:scalab}
\end{figure}
#+END_EXPORT

To illustrate the benefits of such a simulation framework, we 
performed a strong scaling of HPL on a hypothetical platform made of
256 12-core CPUs similar to the ones of the Taurus platform but
interconnected with a two level fat-tree made of 16-port switches and
where the top (resp. bottom) layer comprises 2 (resp. 16) switches
and \SI{10}{\giga\bit\per\sec} Ethernet links.

Previous validation experiments leveraged solely the
default emulation mechanism that allows users to evaluate unmodified MPI
applications. In this mode, every computation of each process is
performed. At scale, this quickly becomes prohibitive and generally
requires much more time than a real-life execution since all MPI
processes are then folded on a single machine. As an illustration,
running HPL for real on 144 cores with a $20,000\times 20,000$ matrix
(i.e., with a memory consumption of \SI{3.2}{\giga\byte} in total) requires less than 20 seconds
whereas a full emulation requires almost two hours. However, as
explained in Section\ref{sec:sg.comp}, since HPC applications are very
regular, it is possible to drastically reduce this cost by modeling
the duration of computation kernels (hence skipping their execution
during the emulation) and folding memory allocations (hence reducing
the memory footprint). With such mechanisms in place, it is possible to simulate
the same scenario (a $20,000\times 20,000$ matrix with 144 processes) /on a
single core of a commodity laptop/ in less than 
two minutes using \SI{43}{\mega\byte} of memory. Simulating an execution
with $256\times12=3,072$ MPI processes requires about one hour and a half
and less than \SI{1.5}{\giga\byte} of memory.

Figure\ref{fig:scalab} depicts a typical scalability evaluation when
the matrix size is fixed to either 20,000 (\SI{3.2}{\giga\byte} in
total) or 65,536 (\SI{34.3}{\giga\byte}). With the smaller matrix,
this quickly leads to a fully network bound scenario where a slowdown
is expected. The values obtained with up to 12 nodes (144 processes) 
are perfectly coherent with real-life experiments since the
application is executed on nodes connected to the same switch. When spreading over more
than one switch (\ie above 196 processes), however, the additional
latency becomes a hindrance, which leads to both a slowdown and an
even faster increase of power consumption. For the larger matrix, we
expected and observed a better scaling. Energy consumption is larger not
only because the whole duration is larger but also because the ratio
of communication to computations is very different.
* Conclusions
#+LaTeX: \label{sec:cl}

Predicting the energy usage of MPI applications through simulation is
a complex problem. In the present article, we have taken first steps
towards solving this problem. We have described the models that can be
used to predict the computation and communication time of MPI
applications, as these models form the basis for our simulator to predict the
energy consumption. Despite the simplicity of these models, obtaining
accurate predictions is not a straight-forward task. Instead, each
model needs to be carefully instantiated and calibrated. To that end,
we have identified several key elements that need to be accounted for
in this calibration process.  The advantage of our simulation process
is that we can obtain accurate predictions by using only one node of a
(homogeneous) compute cluster.
Another key feature of our framework is that it allows users to
study unmodified MPI applications, particularly those that are adaptive to
network performance (\eg by overlapping communications with
computations or by asynchronously pipelining transfers).

In total, we have devised and implemented a first model to obtain energy
predictions of complex MPI applications through simulation.  We have
shown that the energy predictions obtained from simulation match
experimental measurements of the energy usage of MPI
applications. Thus, we have demonstrated that simulation can be a
useful method to obtain faithful insights into the problem of
energy-efficient computing without expensive experimentation.

As future work, we are considering adding energy models for the 
network devices. Network architecture can indeed greatly impact
the performance of applications\cite{Chowdhury} and through smart 
energy-efficient techniques -- like IEEE 802.3az\cite{EEE} that is
putting network ports into low power idle modes when unused -- 
consequent energy savings can be made in HPC infrastructures\cite{EEE_13}.
This network dimension would
increase the potential of SimGrid to be used as a capacity planner
for supercomputer manufacturers and HPC application users.

Another envisioned extension targets the modeling of the energy
consumption of hybrid architectures (\eg multi-core, multi-GPUs,
big.LITTLE processors, ...). Such heterogeneous architectures are
probably the best way to answer energy constraints but their
control-space grows rapidly. SimGrid has successfully been used to
predict the performance of adaptive task-based
runtimes\cite{stanisic_ccpe15} and could guide the
development and the evaluation of energy-aware scheduling heuristics.

#+Latex:\section*{Acknowledgments}

The authors would like to thank the SimGrid team members and
collaborators who contributed to SMPI. This work is partially
supported by the Hac Specis Inria Project Lab, the ANR SONGS
(11-ANR-INFR-13), and the European Mont-Blanc (EC grant 288777)
projects.  Experiments were carried out on the Grid'5000 experimental
testbed, supported by a scientific interest group hosted by Inria and
including CNRS, RENATER, and other Universities and organizations (see
[[https://www.grid5000.fr)]].

# #+LaTeX: % \nocite{*}
# #+LaTeX: \def\raggedright{}

#+LaTeX: \IEEEtriggeratref{36}
#+LaTeX: \bibliographystyle{IEEEtran}
#+LaTeX: \bibliography{simgrid-energy-article,bstcontrol}

* Emacs Setup 							   :noexport:
# Local Variables:
# eval:    (require 'org-install)
# eval:    (org-babel-do-load-languages 'org-babel-load-languages '( (shell . t) (R . t) (perl . t) (ditaa . t) ))
# eval:    (setq org-confirm-babel-evaluate nil)
# eval:    (unless (boundp 'org-latex-classes) (setq org-latex-classes nil))
# eval:    (add-to-list 'org-latex-classes '("IEEEtran"
# "\\documentclass[conference, 10pt]{IEEEtran}\n \[NO-DEFAULT-PACKAGES]\n \[EXTRA]\n  \\usepackage{graphicx}\n  \\usepackage{hyperref}"  ("\\section{%s}" . "\\section*{%s}") ("\\subsection{%s}" . "\\subsection*{%s}")                       ("\\subsubsection{%s}" . "\\subsubsection*{%s}")                       ("\\paragraph{%s}" . "\\paragraph*{%s}")                       ("\\subparagraph{%s}" . "\\subparagraph*{%s}")))
# eval:    (add-to-list 'org-latex-classes '("llncs" "\\documentclass{llncs2e/llncs}\n \[NO-DEFAULT-PACKAGES]\n \[EXTRA]\n"  ("\\section{%s}" . "\\section*{%s}") ("\\subsection{%s}" . "\\subsection*{%s}")                       ("\\subsubsection{%s}" . "\\subsubsection*{%s}")                       ("\\paragraph{%s}" . "\\paragraph*{%s}")                       ("\\subparagraph{%s}" . "\\subparagraph*{%s}")))
# eval:    (add-to-list 'org-latex-classes '("acm-proc-article-sp" "\\documentclass{acm_proc_article-sp}\n \[NO-DEFAULT-PACKAGES]\n \[EXTRA]\n"  ("\\section{%s}" . "\\section*{%s}") ("\\subsection{%s}" . "\\subsection*{%s}")                       ("\\subsubsection{%s}" . "\\subsubsection*{%s}")                       ("\\paragraph{%s}" . "\\paragraph*{%s}")                       ("\\subparagraph{%s}" . "\\subparagraph*{%s}")))
# eval:    (add-to-list 'org-latex-classes '("sig-alternate" "\\documentclass{sig-alternate}\n \[NO-DEFAULT-PACKAGES]\n \[EXTRA]\n"  ("\\section{%s}" . "\\section*{%s}") ("\\subsection{%s}" . "\\subsection*{%s}")                       ("\\subsubsection{%s}" . "\\subsubsection*{%s}")                       ("\\paragraph{%s}" . "\\paragraph*{%s}")                       ("\\subparagraph{%s}" . "\\subparagraph*{%s}")))
# eval:    (setq org-alphabetical-lists t)
# eval:    (setq org-src-fontify-natively t)
# eval:   (setq ispell-local-dictionary "american")
# eval:   (eval (flyspell-mode t))
# eval:   (setq org-todo-keyword-faces '(("FLAWED" . (:foreground "RED" :weight bold))))
# eval:   (custom-set-variables '(org-babel-shell-names (quote ("sh" "bash" "csh" "ash" "dash" "ksh" "mksh" "posh" "zsh"))))
# eval:   (add-to-list 'load-path ".")
# eval:   (require 'ox-extra)
# eval:   (setq org-latex-tables-centered nil)
# eval:   (ox-extras-activate '(ignore-headlines))
# End:
